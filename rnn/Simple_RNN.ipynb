{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train Simple-RNN.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJylzy2EFkzV",
        "colab_type": "code",
        "colab": {},
        "tags": []
      },
      "source": [
        "from utils.datautils import prepare_data, create_vocab\n",
        "prepare_data('train_pos_full.txt', 'train_neg_full.txt', 'data')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "(134000, 2)\n(66000, 2)\n"
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "VOCAB, MAX_LEN = create_vocab('data')"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxBNEeJm-PvD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d3e8a6af-a3df-41ea-c13f-6dae7525c5f5"
      },
      "source": [
        "EMBEDDING_DIM = 100\n",
        "K = 200\n",
        "BATCH_SIZE = 64"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14aTU2Gv-jt6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from utils.glove import load_glove\n",
        "word_to_idx, embeddings, PAD_IDX, words = load_glove('embeddings/glove/glove.twitter.27B.100d.txt', EMBEDDING_DIM)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZg9ZbeK-pXc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "VOCAB_SIZE = len(embeddings)\n",
        "VOCAB_SIZE"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "1193515"
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cmoHWKqH_ei9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from datasets.glove_dataset import GloveDataset\n",
        "\n",
        "train_data = GloveDataset('data/train.csv', MAX_LEN, word_to_idx, PAD_IDX, VOCAB)\n",
        "valid_data = GloveDataset('data/valid.csv', MAX_LEN, word_to_idx, PAD_IDX, VOCAB)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NzlL6eZe_ayM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train_data.__len__(), valid_data.__len__()\n",
        "train_data.__getitem__(778)\n",
        "        "
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "(array([    506,     293,      10,     334,      49,      10,      36,\n            187,     369,      49,     210,      51,      76,      49,\n            456,      49,      11,      73,      10,      36,     456,\n             51,     351,     187,      50,     236,      11,     187,\n            210,     369,     506,     210,      11,     187,      11,\n            293,      47,     137,     187,      76,      11,     210,\n            151,     137,     187,      11,     456,      49,     187,\n            369,      73,      50,      51,     456,     369,      50,\n             51,     187,     187,     369,      49,     199,      11,\n             47,     236,     369,      10,     293,      49,      10,\n             51,      36,     199,      49,      73,     236,      73,\n             10,     187,      49,      10,      36,     137,      51,\n             73,      11,      36,     210,      49,      71,      51,\n             73,     293,      60, 1193514, 1193514, 1193514, 1193514,\n        1193514, 1193514, 1193514, 1193514, 1193514, 1193514, 1193514,\n        1193514, 1193514, 1193514, 1193514, 1193514, 1193514, 1193514,\n        1193514, 1193514, 1193514, 1193514, 1193514, 1193514, 1193514,\n        1193514, 1193514, 1193514, 1193514, 1193514, 1193514, 1193514,\n        1193514, 1193514, 1193514, 1193514, 1193514, 1193514, 1193514,\n        1193514, 1193514, 1193514, 1193514, 1193514, 1193514, 1193514,\n        1193514, 1193514, 1193514, 1193514, 1193514, 1193514, 1193514,\n        1193514, 1193514, 1193514, 1193514]),\n 109,\n 1)"
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4tbpoeh_y9W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "training_params = {\"batch_size\": BATCH_SIZE,\n",
        "                       \"shuffle\": True,\n",
        "                       \"drop_last\": True}\n",
        "\n",
        "validation_params = {\"batch_size\": BATCH_SIZE,\n",
        "                      \"shuffle\": False,\n",
        "                      \"drop_last\": True}\n",
        "train_iterator = DataLoader(train_data, **training_params)\n",
        "valid_iterator = DataLoader(valid_data, **validation_params)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrwlPssMAClz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from models.SIMPLERNN import RNN as RNN"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sHX8LwgOUscH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "INPUT_DIM = VOCAB_SIZE # len(TEXT.vocab)\n",
        "EMBEDDING_DIM = 100\n",
        "HIDDEN_DIM = 256\n",
        "OUTPUT_DIM = 1\n",
        "N_LAYERS = 2\n",
        "BIDIRECTIONAL = True\n",
        "DROPOUT = 0.5\n",
        "PAD_IDX = PAD_IDX # :)\n",
        "\n",
        "model = RNN(INPUT_DIM, \n",
        "            EMBEDDING_DIM, \n",
        "            HIDDEN_DIM, \n",
        "            OUTPUT_DIM, \n",
        "            N_LAYERS, \n",
        "            BIDIRECTIONAL, \n",
        "            DROPOUT, \n",
        "            PAD_IDX)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YG9nTDpH_rbW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ajj5XjO_kYNg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "453d4763-0e0d-4394-cd36-b0027dc23b29"
      },
      "source": [
        "import torch \n",
        "model.embedding.weight.data.copy_(torch.Tensor(embeddings))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"<user> i dm'd you what to do get your followers to follow you on my your new twitter . where is this shindig ? x\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JeAMqa1qgBbn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ywz3PUD7AEkW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "36c4a3c4-3781-487e-ebb4-b01aac4aa122"
      },
      "source": [
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(200000, 2)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Tweet</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>156366</th>\n",
              "      <td>broadways fabulous phantoms ( audio cd the cd ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70313</th>\n",
              "      <td>&lt;user&gt; &lt;user&gt; coil idea piano's everywhere .\\n</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>133644</th>\n",
              "      <td>with &lt;user&gt; while missing &lt;user&gt;\\n</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>172934</th>\n",
              "      <td>alltel ppc 6700 directsync - mobile charging k...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6249</th>\n",
              "      <td>only 100 days until the london olympics ... di...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    Tweet  Label\n",
              "156366  broadways fabulous phantoms ( audio cd the cd ...      0\n",
              "70313      <user> <user> coil idea piano's everywhere .\\n      1\n",
              "133644                 with <user> while missing <user>\\n      0\n",
              "172934  alltel ppc 6700 directsync - mobile charging k...      0\n",
              "6249    only 100 days until the london olympics ... di...      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YhqpGL1DAPKq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "859a236e-c73a-4db9-9bc9-c56b6501f6d7"
      },
      "source": [
        "from utils.mterics import AverageMeter, binary_accuracy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    100000\n",
              "0    100000\n",
              "Name: Label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9h4J42w2HjGr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    num_iter_per_epoch = len(iterator)\n",
        "    losses = AverageMeter()\n",
        "    accuracies = AverageMeter()\n",
        "    model.train()\n",
        "    iter = 0\n",
        "    for batch in iterator:\n",
        "        iter += 1\n",
        "        optimizer.zero_grad()\n",
        "        x_wrd, lengths, labels = batch\n",
        "        x_wrd = torch.LongTensor(x_wrd)\n",
        "        if torch.cuda.is_available():\n",
        "            x_wrd = x_wrd.cuda()\n",
        "            labels = labels.cuda()\n",
        "        \n",
        "        predictions = model(x_wrd).squeeze(1)\n",
        "        \n",
        "        loss = criterion(predictions, labels.float())\n",
        "        \n",
        "        acc = binary_accuracy(predictions, labels)\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "        \n",
        "        losses.update(loss.data, x_wrd.size(0))\n",
        "        accuracy = binary_accuracy(predictions, labels)\n",
        "        accuracies.update(accuracy, x_wrd.size(0))\n",
        "\n",
        "        if (iter % 20 == 0) and (iter > 0):\n",
        "                print(\"[Train - Epoch: {}] , Iteration: {}/{} , Loss: {}, Accuracy: {}\".format(\n",
        "                epoch + 1,\n",
        "                iter,\n",
        "                num_iter_per_epoch,\n",
        "                losses.avg,\n",
        "                accuracies.avg\n",
        "            ))\n",
        "        \n",
        "    return losses.avg.item(), accuracies.avg.item()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z943SRxXaEL-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    \n",
        "    model.eval()\n",
        "    losses = AverageMeter()\n",
        "    accuracies = AverageMeter()\n",
        "    num_iter_per_epoch = len(iterator)\n",
        "\n",
        "    iter = 0\n",
        "    for batch in iterator:\n",
        "        iter += 1\n",
        "        x_wrd, lengths, labels = batch\n",
        "        x_wrd = torch.LongTensor(x_wrd)\n",
        "        if torch.cuda.is_available():\n",
        "            x_wrd = x_wrd.cuda()\n",
        "            labels = labels.cuda()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            predictions = model(x_wrd).squeeze(1)\n",
        "        \n",
        "        loss = criterion(predictions, labels.float())\n",
        "        accuracy = binary_accuracy(predictions, labels)\n",
        "        losses.update(loss.data, x_wrd.size(0))\n",
        "        accuracies.update(accuracy, x_wrd.size(0))\n",
        "\n",
        "        if (iter % 20 == 0) and (iter > 0):\n",
        "            print(\"[Validation - Epoch: {}] , Iteration: {}/{} , Loss: {}, Accuracy: {}\".format(\n",
        "                epoch + 1,\n",
        "                iter,\n",
        "                num_iter_per_epoch,\n",
        "                losses.avg,\n",
        "                accuracies.avg\n",
        "            ))\n",
        "\n",
        "\n",
        "    return losses.avg.item(), accuracies.avg.item()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ISLrZBoNAVDc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import time\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-SJ_NU5Ae-t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "N_EPOCHS = 15\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "\n",
        "    start_time = time.time()\n",
        "    \n",
        "    train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
        "    valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
        "    \n",
        "    end_time = time.time()\n",
        "\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'model-lstm.pt')\n",
        "    \n",
        "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2NYAedU7ReoK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from utils.datautils import prepare_test_data\n",
        "\n",
        "prepare_test_data('test_data.txt', 'data')\n",
        "test_iterator = GloveDataset('data/test.csv', MAX_LEN, word_to_idx, PAD_IDX, VOCAB)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3oWzOQSmBqeZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(model, iterator):\n",
        "    model.eval()\n",
        "    output_arr = []\n",
        "    id = 1\n",
        "    for tweet in iterator: \n",
        "        x_wrd, lengths, label = tweet\n",
        "        x_wrd = torch.LongTensor(x_wrd).unsqueeze(0)\n",
        "        lengths = torch.LongTensor([lengths])\n",
        "        if torch.cuda.is_available():\n",
        "            x_wrd = x_wrd.cuda()\n",
        "            lenghts = lengths.cuda()\n",
        "        prediction = torch.sigmoid(model(x_chr, x_wrd, lengths))\n",
        "        # print()\n",
        "        if int(torch.round(prediction).item()) == 0:\n",
        "            output_arr.append([id, -1])\n",
        "        elif int(torch.round(prediction).item()) == 1:\n",
        "            output_arr.append([id, 1])\n",
        "        else:\n",
        "            raise Exception(\"This should never happen\")\n",
        "        id += 1\n",
        "\n",
        "        if id % 1000 == 0:\n",
        "            print('Predicting example {}/{}'.format(id, len(iterator)))\n",
        "    \n",
        "    return output_arr\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEys2BDjCrvF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred = predict(model, test_iterator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swzI-lneDJSb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from utils.datautils import write_predictions\n",
        "pred_df = write_predictions(pred, 'Simple-RNN.csv', data_dir='predfiles')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}