{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to fine-tune transformers with this repository\n",
    "\n",
    "#### Example commands\n",
    "\n",
    "- RoBERTa\n",
    "\n",
    "```sh\n",
    "$ python -u train.py --log_dir ../logs/roberta-25-06-2020 --dataset in/ --full True --batch_size 64 --model_name roberta --batch_size_validation 64 --val_split 0.005 --description \"roberta run full warmup scheduler\" --grad_clip 1.0\n",
    "```\n",
    "\n",
    "- RoBERTa + Multitask\n",
    "\n",
    "```sh\n",
    "$ python -u train.py --log_dir ../logs/roberta-mt-02-07-2020 --dataset in/ --full True --model_name roberta-multitask --val_split 0.005 --description \"roberta multitask full lm weight 0.5\" --grad_clip 1.0 --multitask True --num_epochs 3\n",
    "```\n",
    "\n",
    "- RoBERTa + Adapters\n",
    "\n",
    "```sh\n",
    "$ python -u train.py --log_dir ../logs/roberta-adapter-30-06-2020 --dataset in/ --full True --model_name roberta-adapter --val_split 0.005 --description \"roberta with adapters and warmup\" --grad_clip 1.0 --num_epochs 8\n",
    "```\n",
    "\n",
    "- RoBERTa Large\n",
    "\n",
    "```sh\n",
    "$ python -u train.py --log_dir ../logs/roberta-large-28-06-2020 --dataset in/ --full True --model_name roberta-large --val_split 0.005 --description \"roberta large with warmup\" --grad_clip 1.0 --batch_size 16 --batch_size_validation 16 --accumulate_grad_batches 4\n",
    "```\n",
    "\n",
    "- BERTweet\n",
    "\n",
    "```sh\n",
    "$ python -u train.py --log_dir ../logs/bertweet-30-06-2020 --dataset in/ --full True --model_name bertweet --val_split 0.005 --description bertweet --grad_clip 1.0\n",
    "```\n",
    "\n",
    "- BERTweet + STL<sub>Electra<sub>LARGE</sub>+STL<sub>BERTweet</sub></sub> (Our Best Model)\n",
    "\n",
    "```sh\n",
    "$ python -u train.py --dataset in/ --full True --val_split 0.005 --grad_clip 1.0 --use_tokn_fast True --model_name bertweet --soft_labels True --description \"bertweet prep soft labels warmup epoch3 (electral soft)\" --log_dir /cluster/scratch/rarade/bertweet-pre-softelectra-wme3-29-07-2020 --num_epochs 2\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-ml] *",
   "language": "python",
   "name": "conda-env-.conda-ml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
